{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "import requests\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import re \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Valles Marineris Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
       " {'title': 'Cerberus Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def init_browser():\n",
    "    executable_path = {\"executable_path\": '/usr/local/bin/chromedriver'}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)\n",
    "\n",
    "def scrape():\n",
    "    browser = init_browser()\n",
    "\n",
    "    # create mars dictionary for mongo\n",
    "    mars_data = {}\n",
    "\n",
    "    #Opens the browser for control\n",
    "    executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "    #Mars News Site\n",
    "    #Sets URL of site to be scraped / page data\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    browser.visit(url)\n",
    "\n",
    "    #Pulling in data\n",
    "    html = browser.html\n",
    "\n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #Mars News Site\n",
    "    #Latest article title\n",
    "    news_title = soup.find('div', class_='content_title').text\n",
    "    #print(news_title)\n",
    "\n",
    "    #Mars News Site\n",
    "    #Latest article text\n",
    "    news_p = soup.find('div', class_='article_teaser_body').text\n",
    "    #print(news_p)\n",
    "\n",
    "    #Featured Space Image\n",
    "    #Sets URL of page to be scraped\n",
    "    image_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars+Feature\"\n",
    "\n",
    "    #Pulling in data\n",
    "    browser.visit(image_url)\n",
    "\n",
    "    #Sets the base URL\n",
    "    baseurl = 'https://www.jpl.nasa.gov'\n",
    "\n",
    "    #Parse with Beautiful Soup\n",
    "    html = browser.html\n",
    "    image_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    #Scrape the URL\n",
    "    image_url = image_soup.find('a', {'id': 'full_image', 'data-fancybox-href': True}).get('data-fancybox-href')\n",
    "    #image_url\n",
    "\n",
    "    #Create the final URL\n",
    "    featured_image_url = baseurl + image_url\n",
    "\n",
    "    #featured_image_url\n",
    "\n",
    "\n",
    "    weather = requests.get(\"https://twitter.com/marswxreport?lang=en\")\n",
    "    wsoup = bs(weather.text, \"html.parser\")\n",
    "\n",
    "    latest = wsoup.find('div', {'class': 'ProfileTimeline'})\n",
    "    latest = latest.find(\"p\", {'class': \"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\"})\n",
    "    mars_weather = latest.text\n",
    "\n",
    "    mars_data = mars_weather\n",
    "\n",
    "\n",
    "    #Mars Facts\n",
    "    #Sets URL of page to be scraped\n",
    "    url = 'https://space-facts.com/mars/'\n",
    "\n",
    "    #Loads the data\n",
    "    html = browser.html\n",
    "\n",
    "    #Read the data to a pandas table\n",
    "    table = pd.read_html(url)\n",
    "    marstab=table[1]\n",
    "\n",
    "    #Mars Facts\n",
    "    #Converts the table to HTML\n",
    "    print(marstab.to_html())\n",
    "\n",
    "    #Mars Facts\n",
    "    #Saving the file\n",
    "    marstab.to_csv('mars_raw_data.csv', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "    #Mars Hemispheres\n",
    "    #URL of page to be scraped - Cerberus\n",
    "    url = 'https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced'\n",
    "    browser.visit(url)\n",
    "\n",
    "    #Pulling in data\n",
    "    html = browser.html\n",
    "\n",
    "    # Create BeautifulSoup object; parse with 'lxml'\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #Image url\n",
    "    cerberus_url = soup.find('div', class_='downloads')\n",
    "    link = cerberus_url.find('a')\n",
    "    cerberus_href = link['href']\n",
    "\n",
    "    #print(cerberus_href)\n",
    "\n",
    "\n",
    "    #Mars Hemispheres\n",
    "    #URL of page to be scraped - Schiaparelli\n",
    "    url = 'https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced'\n",
    "    browser.visit(url)\n",
    "\n",
    "    #Pulling in data\n",
    "    html = browser.html\n",
    "\n",
    "    # Create BeautifulSoup object; parse with 'lxml'\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #Image url\n",
    "    schia_url = soup.find('div', class_='downloads')\n",
    "    link = schia_url.find('a')\n",
    "    schia_href = link['href']\n",
    "\n",
    "    #print(schia_href)\n",
    "\n",
    "    #Mars Hemispheres\n",
    "    #URL of page to be scraped - Syrtis\n",
    "    url = 'https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced'\n",
    "    browser.visit(url)\n",
    "\n",
    "    #Pulling in data\n",
    "    html = browser.html\n",
    "\n",
    "    # Create BeautifulSoup object; parse with 'lxml'\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #Image url\n",
    "    syrtis_url = soup.find('div', class_='downloads')\n",
    "    link = syrtis_url.find('a')\n",
    "    syrtis_href = link['href']\n",
    "    \n",
    "    #print(syrtis_href)\n",
    "\n",
    "    #Mars Hemispheres\n",
    "    #URL of page to be scraped - Syrtis\n",
    "    url = 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'\n",
    "    browser.visit(url)\n",
    "\n",
    "    #Pulling in data\n",
    "    html = browser.html\n",
    "\n",
    "    # Create BeautifulSoup object; parse with 'lxml'\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #Image url\n",
    "    valles_url = soup.find('div', class_='downloads')\n",
    "    link = valles_url.find('a')\n",
    "    valles_href = link['href']\n",
    "\n",
    "    #print(valles_href)\n",
    "\n",
    "    #Mars Hemispheres\n",
    "    #Library of hemisphere images\n",
    "\n",
    "    hemisphere_image_urls = [\n",
    "        {'title': 'Valles Marineris Hemisphere', 'img_url': valles_href},\n",
    "        {'title': 'Syrtis Major Hemisphere', 'img_url': syrtis_href},\n",
    "        {'title': 'Schiaparelli Hemisphere', 'img_url': schia_href},\n",
    "        {'title': 'Cerberus Hemisphere', 'img_url': cerberus_href}\n",
    "    ]\n",
    "\n",
    "    return mars_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
